@inproceedings{devlin2019bert,
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  title     = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages     = {4171--4186},
  year      = {2019}
}

@article{liu2019roberta,
  author  = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  title   = {{RoBERTa}: A Robustly Optimized {BERT} Pretraining Approach},
  journal = {arXiv preprint},
  volume  = {arXiv:1907.11692},
  year    = {2019}
}

@inproceedings{he2021deberta,
  author    = {He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  title     = {{DeBERTa}: Decoding-enhanced {BERT} with Disentangled Attention},
  booktitle = {International Conference on Learning Representations},
  year      = {2021}
}

@article{raffel2020t5,
  author  = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  volume  = {21},
  number  = {140},
  pages   = {1--67},
  year    = {2020}
}

@inproceedings{lewis2020bart,
  author    = {Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  title     = {{BART}: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages     = {7871--7880},
  year      = {2020}
}

@article{rudin2019stop,
  author  = {Rudin, Cynthia},
  title   = {Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead},
  journal = {Nature Machine Intelligence},
  volume  = {1},
  number  = {5},
  pages   = {206--215},
  year    = {2019}
}

@article{doshi2017towards,
  author  = {Doshi-Velez, Finale and Kim, Been},
  title   = {Towards a Rigorous Science of Interpretable Machine Learning},
  journal = {arXiv preprint},
  volume  = {arXiv:1702.08608},
  year    = {2017}
}

@article{lipton2018mythos,
  author  = {Lipton, Zachary C.},
  title   = {The Mythos of Model Interpretability: In machine learning, the concept of interpretability is both important and slippery},
  journal = {Queue},
  volume  = {16},
  number  = {3},
  pages   = {31--57},
  year    = {2018}
}

@book{molnar2022interpretable,
  author    = {Molnar, Christoph},
  title     = {Interpretable Machine Learning: A Guide for Making Black Box Models Explainable},
  year      = {2022},
  edition   = {2nd},
  publisher = {Self-published online},
  url       = {https://christophm.github.io/interpretable-ml-book/}
}

@inproceedings{vaswani2017attention,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  title     = {Attention Is All You Need},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {30},
  pages     = {5998--6008},
  year      = {2017}
}