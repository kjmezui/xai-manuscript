# meta_analysis.py - Version compl√®te
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import statsmodels.api as sm
from statsmodels.formula.api import ols

# Configuration pour les publications scientifiques
plt.rcParams.update({
    'font.size': 10,
    'font.family': 'sans-serif',
    'font.sans-serif': ['Arial', 'Helvetica', 'DejaVu Sans'],
    'axes.titlesize': 12,
    'axes.labelsize': 10,
    'xtick.labelsize': 9,
    'ytick.labelsize': 9,
    'legend.fontsize': 9,
    'figure.titlesize': 14,
    'figure.dpi': 300,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight',
    'savefig.pad_inches': 0.1,
})

# Charger la base de donn√©es
df = pd.read_csv("comprehensive_nlp_models_database.csv")

print("="*80)
print("M√âTA-ANALYSE SYST√âMATIQUE : PERFORMANCE vs EXPLICABILIT√â")
print("="*80)

print(f"\nüìä DESCRIPTION DE L'√âCHANTILLON")
print(f"   ‚Ä¢ Nombre total de mod√®les : {len(df)}")
print(f"   ‚Ä¢ P√©riode : {df['year'].min()} - {df['year'].max()}")
print(f"   ‚Ä¢ Architectures repr√©sent√©es : {', '.join(df['architecture'].unique())}")

print(f"\nüìà STATISTIQUES DESCRIPTIVES")
print(f"   ‚Ä¢ Performance : M = {df['score'].mean():.2f}, SD = {df['score'].std():.2f}")
print(f"   ‚Ä¢ Explicabilit√© (1-5) : M = {df['explainability_score'].mean():.2f}, SD = {df['explainability_score'].std():.2f}")
print(f"   ‚Ä¢ Param√®tres (en millions) : M = {df['parameters_M'].mean():.1f}M, SD = {df['parameters_M'].std():.1f}M")
print(f"   ‚Ä¢ Complexit√© composite : M = {df['complexity_score'].mean():.2f}, SD = {df['complexity_score'].std():.2f}")

print(f"\nüîó ANALYSE DE CORR√âLATION (SPEARMAN)")

# 1. Performance vs Explicabilit√©
corr_perf_exp, p_perf_exp = stats.spearmanr(df['score'], df['explainability_score'])
print(f"   1. Performance ‚Üî Explicabilit√©")
print(f"      œÅ = {corr_perf_exp:.3f}, p = {p_perf_exp:.4f}")
if p_perf_exp < 0.05:
    print(f"      ‚Üí Corr√©lation significative ({'n√©gative' if corr_perf_exp < 0 else 'positive'})")

# 2. Performance vs Complexit√©
corr_perf_comp, p_perf_comp = stats.spearmanr(df['score'], df['complexity_score'])
print(f"\n   2. Performance ‚Üî Complexit√©")
print(f"      œÅ = {corr_perf_comp:.3f}, p = {p_perf_comp:.4f}")
if p_perf_comp < 0.05:
    print(f"      ‚Üí Corr√©lation significative ({'n√©gative' if corr_perf_comp < 0 else 'positive'})")

# 3. Explicabilit√© vs Complexit√©
corr_exp_comp, p_exp_comp = stats.spearmanr(df['explainability_score'], df['complexity_score'])
print(f"\n   3. Explicabilit√© ‚Üî Complexit√©")
print(f"      œÅ = {corr_exp_comp:.3f}, p = {p_exp_comp:.4f}")
if p_exp_comp < 0.05:
    print(f"      ‚Üí Corr√©lation significative ({'n√©gative' if corr_exp_comp < 0 else 'positive'})")

# 4. Performance vs Ann√©e
corr_perf_year, p_perf_year = stats.spearmanr(df['score'], df['year'])
print(f"\n   4. Performance ‚Üî Ann√©e")
print(f"      œÅ = {corr_perf_year:.3f}, p = {p_perf_year:.4f}")
if p_perf_year < 0.05:
    print(f"      ‚Üí Corr√©lation significative ({'n√©gative' if corr_perf_year < 0 else 'positive'})")

print(f"\nüìä R√âGRESSION MULTIPLE")

# Pr√©paration des variables pour la r√©gression
X = df[['complexity_score', 'explainability_score', 'year']]
X = sm.add_constant(X)  # Ajout de l'intercept
y = df['score']

model = sm.OLS(y, X).fit()
print(model.summary())

# Extraire les r√©sultats importants
print(f"\nüîë PRINCIPAUX R√âSULTATS DE LA R√âGRESSION :")
print(f"   ‚Ä¢ R¬≤ = {model.rsquared:.3f}")
print(f"   ‚Ä¢ R¬≤ ajust√© = {model.rsquared_adj:.3f}")

for param in model.params.index:
    if param != 'const':
        p_value = model.pvalues[param]
        coef = model.params[param]
        print(f"   ‚Ä¢ {param}: Œ≤ = {coef:.3f}, p = {p_value:.4f}", end="")
        if p_value < 0.05:
            print(f" (significatif)")
        else:
            print(f" (non significatif)")

print(f"\nüèóÔ∏è ANALYSE PAR ARCHITECTURE")
print("   " + "-"*50)

arch_stats = df.groupby('architecture').agg({
    'score': ['mean', 'std', 'count'],
    'explainability_score': ['mean', 'std'],
    'complexity_score': ['mean', 'std']
}).round(2)

print(arch_stats)

print(f"\nüìã TEST D'HYPOTH√àSE : DIFF√âRENCES ENTRE ARCHITECTURES")

# ANOVA pour les diff√©rences de performance par architecture
print(f"\n   1. ANOVA : Performance ~ Architecture")
model_anova = ols('score ~ C(architecture)', data=df).fit()
anova_table = sm.stats.anova_lm(model_anova, typ=2)
print(anova_table)

if anova_table['PR(>F)'][0] < 0.05:
    print(f"\n      ‚Üí Diff√©rences significatives entre architectures")
    # Test post-hoc Tukey
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    tukey = pairwise_tukeyhsd(
        endog=df['score'],
        groups=df['architecture'],
        alpha=0.05
    )
    print(f"\n      Tests post-hoc Tukey HSD :")
    print(tukey)
else:
    print(f"\n      ‚Üí Pas de diff√©rences significatives entre architectures")

print(f"\nüéØ IMPLICATIONS POUR L'ARTICLE")

# Calculer l'effet taille (Cohen's d) pour la diff√©rence de performance entre mod√®les simples et complexes
# D√©finir simple: explicability_score >= 3, complexe: explicability_score <= 2
simple_models = df[df['explainability_score'] >= 3]
complex_models = df[df['explainability_score'] <= 2]

if len(simple_models) > 0 and len(complex_models) > 0:
    mean_simple = simple_models['score'].mean()
    mean_complex = complex_models['score'].mean()
    std_pooled = np.sqrt((simple_models['score'].var() + complex_models['score'].var()) / 2)
    cohens_d = (mean_complex - mean_simple) / std_pooled
    
    print(f"\n   1. COMPARAISON MOD√àLES SIMPLES vs COMPLEXES :")
    print(f"      ‚Ä¢ Mod√®les simples (explicabilit√© ‚â• 3) : n = {len(simple_models)}, M = {mean_simple:.2f}")
    print(f"      ‚Ä¢ Mod√®les complexes (explicabilit√© ‚â§ 2) : n = {len(complex_models)}, M = {mean_complex:.2f}")
    print(f"      ‚Ä¢ Diff√©rence de performance : {mean_complex - mean_simple:.2f} points")
    print(f"      ‚Ä¢ Taille d'effet (Cohen's d) : {cohens_d:.3f}")
    
    # Test t ind√©pendant
    t_stat, t_p = stats.ttest_ind(simple_models['score'], complex_models['score'], equal_var=False)
    print(f"      ‚Ä¢ Test t : t = {t_stat:.3f}, p = {t_p:.4f}")
    if t_p < 0.05:
        print(f"      ‚Üí Diff√©rence significative")

print(f"\n   2. TENDANCE TEMPORELLE :")
print(f"      ‚Ä¢ Les mod√®les plus r√©cents ont tendance √† avoir une performance plus √©lev√©e")
print(f"      ‚Ä¢ Corr√©lation ann√©e-performance : œÅ = {corr_perf_year:.3f}")

print(f"\n   3. COMPROMIS PERFORMANCE-EXPLICABILIT√â :")
if p_perf_exp < 0.05 and corr_perf_exp < 0:
    print(f"      ‚Ä¢ Confirm√© : corr√©lation n√©gative significative")
    print(f"      ‚Ä¢ Am√©lioration de la performance associ√©e √† une diminution de l'explicabilit√©")
elif p_perf_exp < 0.05 and corr_perf_exp > 0:
    print(f"      ‚Ä¢ Contre-intuitif : corr√©lation positive")
    print(f"      ‚Ä¢ N√©cessite une interpr√©tation approfondie")
else:
    print(f"      ‚Ä¢ Pas de corr√©lation significative d√©tect√©e")

# Cr√©ation des visualisations
print(f"\nüìä CR√âATION DES VISUALISATIONS...")

fig, axes = plt.subplots(2, 3, figsize=(15, 10))

# 1. Scatter: Performance vs Explicabilit√©
sc1 = axes[0,0].scatter(df['explainability_score'], df['score'], 
                       c=df['year'], cmap='viridis', s=100, alpha=0.8, edgecolors='black')
axes[0,0].set_xlabel('Score d\'Explicabilit√© (1-5)')
axes[0,0].set_ylabel('Performance')
axes[0,0].set_title(f'A) Performance vs Explicabilit√©\nœÅ = {corr_perf_exp:.3f}')
plt.colorbar(sc1, ax=axes[0,0], label='Ann√©e')

# Ligne de r√©gression
z = np.polyfit(df['explainability_score'], df['score'], 1)
p = np.poly1d(z)
x_range = np.linspace(df['explainability_score'].min(), df['explainability_score'].max(), 100)
axes[0,0].plot(x_range, p(x_range), 'r--', alpha=0.7, linewidth=2)

# 2. Scatter: Performance vs Complexit√©
sc2 = axes[0,1].scatter(df['complexity_score'], df['score'], 
                       c=df['explainability_score'], cmap='coolwarm', s=100, alpha=0.8, edgecolors='black')
axes[0,1].set_xlabel('Score de Complexit√©')
axes[0,1].set_ylabel('Performance')
axes[0,1].set_title(f'B) Performance vs Complexit√©\nœÅ = {corr_perf_comp:.3f}')
plt.colorbar(sc2, ax=axes[0,1], label='Explicabilit√©')

z = np.polyfit(df['complexity_score'], df['score'], 1)
p = np.poly1d(z)
x_range = np.linspace(df['complexity_score'].min(), df['complexity_score'].max(), 100)
axes[0,1].plot(x_range, p(x_range), 'r--', alpha=0.7, linewidth=2)

# 3. √âvolution temporelle
for arch in df['architecture'].unique():
    subset = df[df['architecture'] == arch]
    axes[0,2].scatter(subset['year'], subset['score'], label=arch, s=80, alpha=0.7)
axes[0,2].set_xlabel('Ann√©e')
axes[0,2].set_ylabel('Performance')
axes[0,2].set_title(f'C) √âvolution Temporelle\nœÅ = {corr_perf_year:.3f}')
axes[0,2].legend()
axes[0,2].grid(True, alpha=0.3)

# 4. Box plot: Performance par architecture
df.boxplot(column='score', by='architecture', ax=axes[1,0])
axes[1,0].set_xlabel('Architecture')
axes[1,0].set_ylabel('Performance')
axes[1,0].set_title('D) Distribution par Architecture')
axes[1,0].tick_params(axis='x', rotation=45)

# 5. Heatmap de corr√©lation
corr_matrix = df[['score', 'explainability_score', 'complexity_score', 'year', 'parameters_M']].corr(method='spearman')
sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, 
            square=True, ax=axes[1,1], cbar_kws={'label': 'Coefficient de Corr√©lation'})
axes[1,1].set_title('E) Matrice de Corr√©lation (Spearman)')

# 6. Bar plot: Performance moyenne vs Explicabilit√© moyenne par architecture
arch_summary = df.groupby('architecture').agg({
    'score': 'mean',
    'explainability_score': 'mean'
}).reset_index()

x = np.arange(len(arch_summary))
width = 0.35

bars1 = axes[1,2].bar(x - width/2, arch_summary['score'], width, label='Performance', color='skyblue')
bars2 = axes[1,2].bar(x + width/2, arch_summary['explainability_score']*20, width, label='Explicabilit√© (√ó20)', color='lightcoral')

axes[1,2].set_xlabel('Architecture')
axes[1,2].set_ylabel('Score')
axes[1,2].set_title('F) Performance vs Explicabilit√© par Architecture')
axes[1,2].set_xticks(x)
axes[1,2].set_xticklabels(arch_summary['architecture'], rotation=45)
axes[1,2].legend()
axes[1,2].grid(True, alpha=0.3, axis='y')

# Ajouter les valeurs sur les barres
for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        axes[1,2].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                      f'{height:.1f}', ha='center', va='bottom', fontsize=8)

plt.suptitle('M√©ta-analyse: Compromis Performance-Explicabilit√© dans les Mod√®les NLP', 
             fontsize=16, fontweight='bold', y=1.02)

plt.tight_layout()
plt.savefig('meta_analysis_complete_results.png', dpi=300, bbox_inches='tight')
plt.close()

print(f"‚úÖ Visualisations sauvegard√©es dans 'meta_analysis_complete_results.png'")

print(f"\n" + "="*80)
print("üìù R√âSUM√â POUR LA R√âDACTION DE L'ARTICLE")
print("="*80)

print(f"\n1. CONTEXTE EXP√âRIMENTAL :")
print(f"   ‚Ä¢ √âchantillon : {len(df)} mod√®les NLP (2019-2023)")
print(f"   ‚Ä¢ M√©thode : M√©ta-analyse syst√©matique de la litt√©rature")
print(f"   ‚Ä¢ Variables : Performance, Explicabilit√©, Complexit√©, Architecture")

print(f"\n2. R√âSULTATS CL√âS :")
print(f"   ‚Ä¢ Performance moyenne : {df['score'].mean():.2f} (SD = {df['score'].std():.2f})")
print(f"   ‚Ä¢ Explicabilit√© moyenne : {df['explainability_score'].mean():.2f}/5")
print(f"   ‚Ä¢ Corr√©lation performance-explicabilit√© : œÅ = {corr_perf_exp:.3f} (p = {p_perf_exp:.4f})")
print(f"   ‚Ä¢ Corr√©lation performance-complexit√© : œÅ = {corr_perf_comp:.3f} (p = {p_perf_comp:.4f})")

print(f"\n3. INTERPR√âTATION :")
if p_perf_exp < 0.05 and corr_perf_exp < 0:
    print(f"   ‚Ä¢ Le trade-off performance-explicabilit√© est confirm√© statistiquement")
    print(f"   ‚Ä¢ Les mod√®les plus performants tendent √† √™tre moins explicables")
elif p_perf_exp >= 0.05:
    print(f"   ‚Ä¢ Aucune corr√©lation significative n'a √©t√© d√©tect√©e")
    print(f"   ‚Ä¢ Le trade-off pourrait √™tre moins prononc√© qu'attendu")

print(f"\n4. IMPLICATIONS :")
print(f"   ‚Ä¢ Pour la recherche : N√©cessit√© de d√©velopper des m√©triques d'explicabilit√© standardis√©es")
print(f"   ‚Ä¢ Pour la pratique : Guide pour le choix de mod√®les selon les contraintes")
print(f"   ‚Ä¢ Pour l'industrie : Importance de l'explicabilit√© pour le d√©ploiement responsable")

print(f"\n" + "="*80)
print("‚úÖ ANALYSE TERMIN√âE - PR√äT POUR LA R√âDACTION")
print("="*80)