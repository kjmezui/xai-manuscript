import pandas as pd
import numpy as np
import os

print("√âTAPE 1 : Fusion des donn√©es...")

# V√©rifier que les fichiers existent
required_files = ['manual_model_performance.csv', 'huggingface_models_with_proxy.csv']
missing_files = [f for f in required_files if not os.path.exists(f)]

if missing_files:
    print(f"‚ùå Fichiers manquants: {missing_files}")
    print("Veuillez d'abord ex√©cuter:")
    print("1. manual_performance_dataset.py")
    print("2. collect_data.py (corrig√©)")
    exit(1)

# Charger les donn√©es
print("Chargement des donn√©es...")
collected = pd.read_csv("huggingface_models_with_proxy.csv")
manual = pd.read_csv("manual_model_performance.csv")

print(f"Donn√©es collect√©es: {len(collected)} mod√®les")
print(f"Donn√©es manuelles: {len(manual)} mod√®les")

# Fusionner les donn√©es
print("Fusion des datasets...")
merged = pd.merge(
    collected, 
    manual[['model_id', 'performance_value', 'performance_metric', 'explicability_proxy', 'paper', 'notes']], 
    on='model_id', 
    how='left', 
    suffixes=('_collected', '_manual')
)

print(f"Dataset fusionn√©: {len(merged)} mod√®les")

# Cr√©er une variable de performance unifi√©e
def get_best_performance(row):
    # Priorit√© 1: Donn√©es manuelles (plus fiables)
    if pd.notna(row.get('performance_value')):
        return row['performance_value']
    
    # Priorit√© 2: Donn√©es collect√©es
    perf_cols = [col for col in row.index if col.startswith('perf_')]
    for col in perf_cols:
        if pd.notna(row[col]):
            return row[col]
    
    return np.nan

merged['performance_final'] = merged.apply(get_best_performance, axis=1)

# Cr√©er une variable d'explicabilit√© unifi√©e
def get_explicability_proxy(row):
    if pd.notna(row.get('explicability_proxy')):
        return row['explicability_proxy']
    elif pd.notna(row.get('model_type_proxy')):
        return row['model_type_proxy']
    else:
        return 'unknown'

merged['explicability_final'] = merged.apply(get_explicability_proxy, axis=1)

# Coder ordinalement l'explicabilit√©
explicability_mapping = {
    'lightweight': 1,
    'medium': 2, 
    'complex': 3,
    'unknown': np.nan
}
merged['explicability_ordinal'] = merged['explicability_final'].map(explicability_mapping)

# Sauvegarder
output_file = "merged_analysis_dataset.csv"
merged.to_csv(output_file, index=False)

print(f"\n‚úÖ Dataset fusionn√© sauvegard√© dans '{output_file}'")
print(f"   Mod√®les avec performance: {merged['performance_final'].notna().sum()}/{len(merged)}")
print(f"   Mod√®les avec explicabilit√©: {merged['explicability_ordinal'].notna().sum()}/{len(merged)}")

# Aper√ßu des donn√©es
print("\nüìä APER√áU DES DONN√âES FUSIONN√âES:")
print(merged[['model_id', 'performance_final', 'explicability_final', 'explicability_ordinal']].head(10))